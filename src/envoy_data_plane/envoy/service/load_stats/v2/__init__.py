# Generated by the protocol buffer compiler.  DO NOT EDIT!
# sources: envoy/service/load_stats/v2/lrs.proto
# plugin: python-betterproto
from dataclasses import dataclass
from datetime import timedelta
from typing import AsyncIterable, AsyncIterator, Dict, Iterable, List, Union

import betterproto
from betterproto.grpc.grpclib_server import ServiceBase
import grpclib


@dataclass(eq=False, repr=False)
class LoadStatsRequest(betterproto.Message):
    """
    A load report Envoy sends to the management server. [#not-implemented-
    hide:] Not configuration. TBD how to doc proto APIs.
    """

    # Node identifier for Envoy instance.
    node: "___api_v2_core__.Node" = betterproto.message_field(1)
    # A list of load stats to report.
    cluster_stats: List[
        "___api_v2_endpoint__.ClusterStats"
    ] = betterproto.message_field(2)


@dataclass(eq=False, repr=False)
class LoadStatsResponse(betterproto.Message):
    """
    The management server sends envoy a LoadStatsResponse with all clusters it
    is interested in learning load stats about. [#not-implemented-hide:] Not
    configuration. TBD how to doc proto APIs.
    """

    # Clusters to report stats for. Not populated if *send_all_clusters* is true.
    clusters: List[str] = betterproto.string_field(1)
    # If true, the client should send all clusters it knows about. Only clients
    # that advertise the "envoy.lrs.supports_send_all_clusters" capability in
    # their :ref:`client_features<envoy_api_field_core.Node.client_features>`
    # field will honor this field.
    send_all_clusters: bool = betterproto.bool_field(4)
    # The minimum interval of time to collect stats over. This is only a minimum
    # for two reasons: 1. There may be some delay from when the timer fires until
    # stats sampling occurs. 2. For clusters that were already feature in the
    # previous *LoadStatsResponse*, any traffic    that is observed in between
    # the corresponding previous *LoadStatsRequest* and this
    # *LoadStatsResponse* will also be accumulated and billed to the cluster.
    # This avoids a period    of inobservability that might otherwise exists
    # between the messages. New clusters are not    subject to this
    # consideration.
    load_reporting_interval: timedelta = betterproto.message_field(2)
    # Set to *true* if the management server supports endpoint granularity
    # report.
    report_endpoint_granularity: bool = betterproto.bool_field(3)


class LoadReportingServiceStub(betterproto.ServiceStub):
    async def stream_load_stats(
        self,
        request_iterator: Union[
            AsyncIterable["LoadStatsRequest"], Iterable["LoadStatsRequest"]
        ],
    ) -> AsyncIterator["LoadStatsResponse"]:

        async for response in self._stream_stream(
            "/envoy.service.load_stats.v2.LoadReportingService/StreamLoadStats",
            request_iterator,
            LoadStatsRequest,
            LoadStatsResponse,
        ):
            yield response


class LoadReportingServiceBase(ServiceBase):
    async def stream_load_stats(
        self, request_iterator: AsyncIterator["LoadStatsRequest"]
    ) -> AsyncIterator["LoadStatsResponse"]:
        raise grpclib.GRPCError(grpclib.const.Status.UNIMPLEMENTED)

    async def __rpc_stream_load_stats(self, stream: grpclib.server.Stream) -> None:
        request_kwargs = {"request_iterator": stream.__aiter__()}

        await self._call_rpc_handler_server_stream(
            self.stream_load_stats,
            stream,
            request_kwargs,
        )

    def __mapping__(self) -> Dict[str, grpclib.const.Handler]:
        return {
            "/envoy.service.load_stats.v2.LoadReportingService/StreamLoadStats": grpclib.const.Handler(
                self.__rpc_stream_load_stats,
                grpclib.const.Cardinality.STREAM_STREAM,
                LoadStatsRequest,
                LoadStatsResponse,
            ),
        }


from ....api.v2 import core as ___api_v2_core__
from ....api.v2 import endpoint as ___api_v2_endpoint__
